{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Práctica de aprendizaje automático (parte 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrega este cuaderno habiendo **ejecutado todas las celdas**. Incluye en la entrega **todos los ficheros necesarios para su ejecución**.\n",
    "\n",
    "Asegúrate de que la presentación está bien estructurada: Se valorará la **claridad, concisión, y completitud** del informe.\n",
    "\n",
    "Se trata de una práctica abierta: **sé intrépido y explora**. \n",
    "\n",
    "1. Describe las características de los datos:\n",
    "    * Tipo de datos (e.g. [https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)))\n",
    "    * Número de ejemplos de cada una de las clases.\n",
    "    * Número y tipo (nominales no ordenados, nominales ordenados, numéricos) de atributos.\n",
    "\n",
    "Esta información se debería utilizar en el análisis; por ejemplo, si se selecciona un atributo para la predicción, ¿es clara su relevancia por el tipo de información que proporciona de acuerdo con nuestro conocimiento experto sobre el área?\n",
    "    \n",
    "2. Detalla la metodología utilizada:\n",
    "    * Partición de los datos: tamaño de los conjuntos de entrenamiento y test, uso de estratificación en el muestreo.\n",
    "    * Preprocesamiento: codificación de los atributos, construcción y selección de características, normalización, etc. (¡solo se debe utilizar la información del conjunto de entrenamiento!)\n",
    "    * Determinación de los hiperparámetros; por ejemplo, mediante búsqueda en rejilla y validación cruzada.\n",
    "    * Estimación del error de generalización y su incertidumbre.\n",
    "2. Resume los resultados en gráficas y tablas.\n",
    "3. Elabora esta información e ilustra tus observaciones con los resultados obtenidos.\n",
    "4. Proporciona una recomendación final:\n",
    "    * Tipo de clasificador.\n",
    "    * Configuración del clasificador (arquitectura, hiperparámetros, etc.) y método de entrenamiento (función de coste, método de optimización, uso de técnicas de regularización,...)\n",
    "    * Para el predictor final, proporciona los errores de entrenamiento, validación cruzada y test.\n",
    "5. Resume las conclusiones del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Construcción de un clasificador en una base de datos real (4.5 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/german_credit_data.csv', sep=';')\n",
    "# Source: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)\n",
    "# This dataset classifies people described by a set of attributes as good or bad credit risks. Comes in two formats (one all numeric). Also comes with a cost matrix\n",
    "\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 'default'\n",
    "feature_names = list(df.columns)\n",
    "feature_names.remove(class_label)\n",
    "print(feature_names)\n",
    "X = df[feature_names].values\n",
    "y = df[class_label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadísticos básicos de cada atributo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos codificados de forma numérica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/german_credit_data_numeric.csv', sep=';')\n",
    "class_label = 'Class'\n",
    "feature_names = list(df.columns)\n",
    "feature_names.remove(class_label)\n",
    "print(feature_names)\n",
    "X = df[feature_names].values\n",
    "y = df[class_label].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogramas suavizados de cada atributo en cada clase. El color indica la clase (\"default\"/\"no default\"):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 21))\n",
    "n_cols_plot = 4\n",
    "n_rows_plot = int(len(feature_names) / n_cols_plot)\n",
    "for i,n in enumerate(feature_names):\n",
    "    plt.subplot(n_rows_plot, n_cols_plot, i+1)\n",
    "    aux = 'Density' if i%n_cols_plot == 0 else ''\n",
    "    df.groupby('Class')[n].plot(kind='kde', title='Hist. de '+n)\n",
    "    plt.ylabel(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo y chequeo de su calidad usando 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda entrena un modelo y lo evalúa en varias particiones training-test diferentes de los datos. El resultado es un score medio junto a su desviación estándar. El tipo de modelo (Naïve Bayes / árbol de decisión / knn/ regresión logística / red neuronal) y parámetros empleados deberán ser seleccionados para que dicho resultado sea el mejor posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# otros clasificadores (del notebook p4_01)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1) # DecisionTreeClassifier(max_depth=3)\n",
    "scores = cross_val_score(clf, X, y, cv=10) # 10-fold cross-validation\n",
    "print('Precisión en cada una de las particiones: ', scores)\n",
    "print('Estimación de la precisión por validación cruzada: {:.2f} +/- {:.2f}'.format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Responde aquí a las siguientes preguntas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Haz una gráfica que muestre la dependencia de la precisión de un clasificador de vecinos próximos con el número de vecinos. Si es más conveniente, utiliza gráficas en escala logarítmica para alguno de los ejes (`semilogx`, `semilogy`, `loglog`).\n",
    "* Utilizando los conceptos de sub- y sobreajuste:\n",
    "    * Comenta los resultados cuando el número de vecinos es pequeño.\n",
    "    * Comenta los resultados cuando el número de vecinos es grande.\n",
    "    * Explica el significado del valor de la precisión cuando el número de vecinos toma el valor mayor posible.\n",
    "* ¿Cuál es la mejor precisión que se alcanza con k-nn y para qué k (valor de `n_neighbours`)?\n",
    "* ¿Cuál es la mejor precisión que se alcanza con un árbol de decisión y con qué profundidad máxima (valor de `max_depth`)? Para ello, haz una gráfica que muestre la dependencia de la precisión con la profundidad máxima del árbol. Comenta los resultados.\n",
    "* ¿Cuál es la mejor precisión que se alcanza con una red neuronal con una sola capa oculta y con qué configuración (valor de `hidden_layer_sizes`)? Para ello, haz una gráfica que muestre la dependencia de la precisión con el número de nodos en la capa oculta. Comenta los resultados.\n",
    "* ¿Cuál es la mejor precisión que se alcanza con una red neuronal con varias capas ocultas y con qué configuración? Para ello, haz una gráfica que muestre la dependencia de la precisión con el número de capas ocultas, suponiendo constante el número de nodos en cada capa oculta. Comenta los resultados.\n",
    "* Resume los resultados y conclusiones del estudio realizado.\n",
    "\n",
    "**Además de gráficas, puede ser conveniente presentar los resultados en forma de tablas.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[POR HACER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones, en lugar de utilizar modelos más complejos, es más útil invertir más tiempo en el procesamiento de los datos para conseguir mejores resultados.\n",
    "\n",
    "En este apartado vas a investigar mecanismos para preparar los datos y obtener (en principio) mejores resultados: construcción y selección de atributos, preprocesamiento (detección de outliers, missing values, centrado y escalado).\n",
    "\n",
    "Razona por qué decides probar o ignorar alguno de estos métodos, y cómo cambian los resultados al aplicarlos (puedes crear tantas celdas como consideres oportunas).\n",
    "Usa tablas, gráficas y código, según sea necesario, para ilustrar tus observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se determina el valor de los hiperparámetros?\n",
    "\n",
    "Para determinar el valor de los hiperparámetros de un modelo realizaremos una búsqueda en una rejilla. De entre los valores considerados seleccionaremos los que maximicen la estimación por validación cruzada (K = 10) de la tasa de acierto.\n",
    "\n",
    "Adapta el código que encontrarás en \n",
    "[https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py](https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py)\n",
    "a este problema. \n",
    "\n",
    "En los tutoriales\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html](\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "[https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "hay información sobre cada uno de los hiper-parámetros. \n",
    "Puedes elegir el conjunto de hiperparametros en el que se realiza la optimización. \n",
    "Antes de elegir la rejilla de hiperparámetros, asegúrate de que entiendes su para asegurarte que tiene sentido la búsqueda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo se estima el error de generalización?\n",
    "\n",
    "Estimaremos el error de generalización de cada clasificador usando *Nested Cross Validation*. \n",
    "\n",
    "\n",
    "Adapta el código que encontrarás en https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html para resolver este problema con una red neuronal. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluye aquí código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuál es el mejor clasificador?\n",
    "\n",
    "* De acuerdo con los resultados de los anteriores apartados, indica cuál es el mejor clasificador encontrado.\n",
    "* ¿Cuáles son los valores de los hiperparámetros utilizados para configurar y entrenar tal  clasificador?\n",
    "* ¿cuáles son los valores de los parámetros del clasificador entrenado?\n",
    "* Proporciona una estimación del error de generalización por validación cruzada, así como de la incertidumbre de dicha estimación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones.\n",
    "Resume los resultados y conclusiones del estudio que has realizado.\n",
    "\n",
    "\n",
    "[POR HACER]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
